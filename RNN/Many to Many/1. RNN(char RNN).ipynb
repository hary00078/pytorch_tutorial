{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 훈련 데이터 전처리하기\n",
    "## <font color = \"purple\">문자 시퀀스 apple을 입력받으면 pple!를 출력하는 RNN을 구현합니다. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 5\n"
     ]
    }
   ],
   "source": [
    "input_str = \"apple\"\n",
    "label_str = \"pple!\"\n",
    "char_vocab = sorted(list(set(input_str + label_str)))\n",
    "vocab_size = len(char_vocab)\n",
    "print(\"문자 집합의 크기 :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "# 문자 집합에 고유 정수를 부여합니다\n",
    "char_to_idx = {word : i for i, word in enumerate(char_vocab)}\n",
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "# 정수로부터 문자를 얻을 수 있는 index_to_char를 만듭니다\n",
    "index_to_char = {}\n",
    "for key, value in char_to_idx.items():\n",
    "    index_to_char[value] = key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_idx[c] for c in input_str]\n",
    "y_data = [char_to_idx[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4, 3, 2]]\n",
      "[[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [x_data]\n",
    "y_data = [y_data]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "tensor([[4, 4, 3, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : torch.Size([1, 5, 5])\n",
      "레이블의 크기: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터의 크기 :\", X.shape)\n",
    "print(\"레이블의 크기:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size # vocab_size = 5\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "# 나중에 정확도를 측정할 떄는 배치 차원과 time-step차원을 하나로 합친다.\n",
    "print(outputs.view(-1, input_size).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(Y.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 loss : tensor(1.5849, grad_fn=<NllLossBackward>) prediction:  [[4 2 2 2 2]] true Y: [[4, 4, 3, 2, 0]] prediction str: peeee\n",
      "epoch : 10 loss : tensor(0.0579, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 20 loss : tensor(0.0047, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 30 loss : tensor(0.0016, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 40 loss : tensor(0.0010, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 50 loss : tensor(0.0007, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 60 loss : tensor(0.0007, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 70 loss : tensor(0.0006, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 80 loss : tensor(0.0006, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 90 loss : tensor(0.0005, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "epoch : 100 loss : tensor(0.0005, grad_fn=<NllLossBackward>) prediction:  [[4 4 3 2 0]] true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n"
     ]
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        #아래 세 줄은 모델이 실제 어떻게 예측했는지를 확인하기 위한 코드\n",
    "        result = outputs.data.numpy().argmax(axis=2) # 최종 예측값인 각 time-step 별 5차원 벡터에 대해서 가장 높은 값의 인덱스를 선택\n",
    "        result_str = ''.join([index_to_char[c] for c in np.squeeze(result)])\n",
    "        print(\"epoch :\", i, \"loss :\", loss, \"prediction: \", result, \"true Y:\", y_data, \"prediction str:\", result_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
