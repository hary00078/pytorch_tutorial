{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습힙니다 :  cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA  = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습힙니다 : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', train = True, transform=transforms.ToTensor(), download = True)\n",
    "'''\n",
    "첫번째 인자 root는 MNIST 데이터를 다운로드 받을 경로입니다. \n",
    "두번째 인자 train은 인자로 True를 주면, MNIST의 훈련 데이터를 리턴받으며 False를 주면 테스트 데이터를 리턴받습니다. \n",
    "세번째 인자 transform은 현재 데이터를 파이토치 텐서로 변환해줍니다. \n",
    "네번째 인자 download는 해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미입니다.\n",
    "'''\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', train = False, transform=transforms.ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n첫번째 인자인 DataLoader는 로드할 대상을 의미하며, \\n두번째 인자인 batch_size는 배치 크기, \\nshuffle은 매 에포크마다 미니 배치를 셔플할 것인지의 여부, \\ndrop_last는 마지막 배치를 버릴 것인지를 의미합니다.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset = mnist_train, batch_size = batch_size, shuffle = True,drop_last = True)\n",
    "\"\"\"\n",
    "첫번째 인자인 DataLoader는 로드할 대상을 의미하며, \n",
    "두번째 인자인 batch_size는 배치 크기, \n",
    "shuffle은 매 에포크마다 미니 배치를 셔플할 것인지의 여부, \n",
    "drop_last는 마지막 배치를 버릴 것인지를 의미합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(784, 10, bias = True)\n",
    "#bias는 편향 b를 사용할 것인지를 나타냅니다.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 cost :  tensor(0.2537, grad_fn=<AddBackward0>)\n",
      "epoch :  1 cost :  tensor(0.2533, grad_fn=<AddBackward0>)\n",
      "epoch :  2 cost :  tensor(0.2529, grad_fn=<AddBackward0>)\n",
      "epoch :  3 cost :  tensor(0.2526, grad_fn=<AddBackward0>)\n",
      "epoch :  4 cost :  tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "epoch :  5 cost :  tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "epoch :  6 cost :  tensor(0.2518, grad_fn=<AddBackward0>)\n",
      "epoch :  7 cost :  tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "epoch :  8 cost :  tensor(0.2514, grad_fn=<AddBackward0>)\n",
      "epoch :  9 cost :  tensor(0.2508, grad_fn=<AddBackward0>)\n",
      "epoch :  10 cost :  tensor(0.2506, grad_fn=<AddBackward0>)\n",
      "epoch :  11 cost :  tensor(0.2505, grad_fn=<AddBackward0>)\n",
      "epoch :  12 cost :  tensor(0.2499, grad_fn=<AddBackward0>)\n",
      "epoch :  13 cost :  tensor(0.2500, grad_fn=<AddBackward0>)\n",
      "epoch :  14 cost :  tensor(0.2497, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for idx, samples in enumerate(data_loader):\n",
    "        X, Y = samples\n",
    "        X = X.view(-1, 28*28)\n",
    "        prediction = linear(X)\n",
    "        cost = F.cross_entropy(prediction, Y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost / len(data_loader)\n",
    "    print(\"epoch : \", epoch, \"cost : \", avg_cost)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8695)\n"
     ]
    }
   ],
   "source": [
    "X_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "Y_test = mnist_test.test_labels\n",
    "\n",
    "prediction = linear(X_test)\n",
    "correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "accuarcy = correct_prediction.float().mean()\n",
    "print(accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
